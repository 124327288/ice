Release notes for Ice 3.3.0
===========================

INTRO TBD

The sections below describe the new features and fixes included in
this release. See the section titled "Upgrading your application"
for more information about migrating to a new Ice release, including
details about APIs that have been deprecated or removed in this
release.

Note that because the Python, Ruby, and PHP language mappings use the
C++ Ice run time, they automatically benefit from fixes to the C++ Ice
core even if those language mappings are not explicitly mentioned
below.


New Features
============

This section discusses the significant enhancements offered in this
release.


Non-blocking AMI
----------------

Ice 3.3.0 includes an important change in the semantics of AMI
requests: Ice now guarantees that the calling thread will never block
when issuing an asynchronous invocation.

In previous releases, the Ice run time blocked the calling thread
until the request was accepted by the local transport buffer.
Typically this occurred quickly enough that AMI requests appeared to
be non-blocking, and applications may have been designed based on that
assumption. In fact, however, there were many opportunities for an AMI
request to block:

* If a connection was not yet established, the calling thread would
  block while Ice attempted to resolve DNS host names and open a
  connection to one of the proxy's endpoints.

* When using an indirect proxy, the calling thread blocked while Ice
  issued a request to the locator.

* If the local network buffer was full, Ice blocked until there was
  room for the entire message.

An application could use timeouts to avoid blocking indefinitely, but
it was not safe to assume that an AMI request would never block.

As of this release, Ice behaves quite differently when processing an
AMI request. An initial attempt is made to send the request
synchronously, without blocking. This includes the activities
mentioned above, such as establishing a connection and contacting a
locator. If any of these activities would block, Ice queues the
request and returns immediately. Queued requests are sent in the
background; in C++ and Java, an internal thread performs this duty,
while in .NET Ice uses the platform's asynchronous I/O facility.

An application can still use timeouts if necessary, and in fact
AMI timeouts have much greater precision in this release because they
no longer depend on the interval defined by the configuration property
Ice.MonitorConnections.

The new non-blocking nature of AMI requests is especially useful for
a graphical application, which in previous releases needed to use some
potentially elaborate workarounds to avoid impacting the interactive
responsiveness of its user interface.

Along with this new capability comes new responsibility. There now
exists the potential for accumulating an unlimited number of queued
AMI requests in the Ice run time, consuming an equally unlimited
amount of memory. To that end, Ice provides new APIs that enable an
application to implement its own flow-control logic:

* Asynchronous proxy methods now return a boolean value to indicate
  whether the AMI request was sent synchronously. If the method
  returns false, it means the Ice run time has queued the request.

* An AMI callback can be notified when a queued request is sent.

There have been other notable changes to the asynchronous invocation
model:

* AMI now supports oneway requests. The callback object is required
  to implement the ice_response and ice_exception methods as usual,
  but ice_response is not called for oneway requests. Ice calls the
  ice_exception method if an error occurs before a oneway request
  is accepted by the local transport buffer.

* Batch requests can be flushed for individual proxies using two new
  proxy methods:

  void ice_flushBatchRequests()
  bool ice_flushBatchRequests_async(callback)

  As its name implies, the second method allows you to flush batch
  requests using the non-blocking AMI semantics.

* Ice guarantees that the thread making an AMI request is never used
  to invoke a method in the callback object. Instead, all invocations
  on an AMI callback are now performed by a thread from an Ice thread
  pool. As a result, it is now safe to hold a non-recursive lock while
  making an AMI request, whereas in previous releases doing so had the
  potential for causing a deadlock if the callback acquired the same
  lock.

* A thread that invokes an asynchronous proxy method must be prepared
  to catch CommunicatorDestroyedException if it is possible for the
  communicator to be destroyed while the thread is active. All other
  exceptions are passed to the ice_exception method of the callback
  object. This behavior differs from previous releases, in which no
  exceptions could be raised by an asynchronous proxy method.

Please refer to the "Asynchronous Programming" chapter in the Ice
manual for more information on the new AMI semantics.


Scalability improvements in Glacier2
------------------------------------

The new AMI semantics made it possible to significantly improve the
scalability of the Glacier2 router. In previous releases Glacier2 used
the thread-per-connection concurrency model in an effort to prevent
the activities of one client from impacting other clients. The main
disadvantage of using thread-per-connection is that it did not scale
as well as the thread pool concurrency model.

Glacier2 now uses the thread pool for greater scalability, and takes
advantage of non-blocking AMI to ensure that slow or misbehaving
clients cannot affect the router's other clients.

The router's buffering mode has also been enhanced so that at most
two threads are used, rather than a thread for each client as in prior
versions. However, it is no longer necessary to use buffered mode
solely to gain better separation between clients; Glacier2 now
provides the same separation regardless of its buffering mode. The
primary motivations for enabling buffering are to give the router an
opportunity to batch oneway requests, and to support its ability to
override pending requests.


Highly-available IceStorm
-------------------------

TBD


Freeze transactional evictor
----------------------------

This release adds a new kind of Freeze Evictor in which all write
operations are automatically enclosed in a Freeze transaction. This
new Evictor gives applications write-ordering guarantees, allows
developers to enclose several operations in the same transaction (when
using collocated invocations), and helps ensure data consistency when
recovering from a crash.

See the "Freeze" chapter in the Ice manual for complete details.


Administrative facility
-----------------------

Ice supports an extensible new facility for adding administrative
capabilities to your applications. When an application is properly
configured, the Ice run time creates a dedicated object adapter that
hosts a single object known as the "admin" object. Each administrative
capability is represented by a separate facet of the admin object.

Ice supplies two facets by default: the Process facet enables a server
activation service such as IceGrid to gracefully terminate the
process, and the Properties facet allows remote inspection of a
program's configuration. Applications can also install their own
facets, and easily control which facets are enabled using a
configuration property.

IceBox extends the facility to make its ServiceManager interface
available via an administrative facet, giving you the ability to
remotely start and stop individual IceBox services. The facility is
also integrated into IceGrid and its administrative clients. You can
find more details in the relevant chapters of the Ice manual.

For more information on the administrative facility, see the "Ice
Run Time" chapter.


Dynamic network interfaces
--------------------------

Ice server endpoints that are configured to listen on all local
interfaces now listen on INADDR_ANY/0.0.0.0 rather than listening
separately on each of the interfaces that were found at the time the
server started. This means that if a new interface becomes available
while the server is running, Ice will be able to receive and process
requests using that interface.

Note that, if an interface change occurs, an object adapter does not
automatically refresh the list of endpoints that it embeds in newly-
created proxies. Rather, an application must instruct the object
adapter to refresh its endpoint list using the new operation
refreshPublishedEndpoints. See the "Ice Run Time" chapter in the Ice
manual for further details.


IPv6 and UDP multicast
----------------------

Ice 3.3.0 includes support for IPv6 as well as UDP multicast. Both of
these features are controlled via configuration properties.

IPv6 is disabled by default, and can be enabled using the new property
Ice.IPv6. Another new property, Ice.IPv4, allows you to disable the
use of IPv4 if you prefer to use only IPv6 in your application.

Using UDP multicast in an application simply requires that you select
an appropriate IP address for your endpoints.

Appendix D of the Ice manual explains the syntax for specifying IPv6
and UDP multicast addresses in endpoints.



Updated C# mapping
------------------

New metadata allows .NET users to map Slice sequence types into
generic .NET 2.0 collections:

  // Slice
  ["clr:generic:List"] sequence<int> S;

maps to:

  // C#
  System.Collections.Generic.List<int> S;

Additional collection types are also supported.

Slice dictionary types now map to a generic .NET 2.0 collection by
default:

  // Slice
  dictionary<string, int> D;

maps to:

  // C#
  System.Collections.Generic.Dictionary<string, int> D;

If you prefer to use the previous .NET 1.1 mapping to DictionaryBase,
you will need to annotate your Slice definitions with the metadata
tag "clr:collection".



Platforms and compilers
=======================

The list shown below represents changes or additions to the platforms
and compilers that Ice supports:

* Red Hat Enterprise Linux 4.6 and 5.1 (i386 and x86_64)
* SuSE Enterprise Linux Server 10 SP1 (i386 and x86_64)
* Microsoft Windows Vista (x86 and x64)
* Mac OS X 10.5
* Solaris 10 SPARC and x86 (32- and 64-bit)
* Microsoft Visual Studio 2005 SP1
* Microsoft Visual Studio 2008

Express editions of Microsoft compilers are only supported by the C++
language mapping; Ice for .NET requires Visual Studio 2005 or 2008.


Fixes and improvements
======================

IPv4/IPv6/TCP.Backlog


Desupported components
======================

This section describes Ice components that are no longer supported.


Java2
-----

Ice for Java now requires Java5 or Java6 as its compilation and run-
time environment. See the section titled "Deprecated APIs" for
additional information on the Java language mapping.

To continue using Java2 for your application, you must use a previous
Ice release. Note however that ZeroC only provides support for the
most recent Ice release unless you have a support contract.


Thread per connection concurrency model
---------------------------------------

The improvements introduced by the non-blocking AMI feature (see
"Background I/O") have made this concurrency model unnecessary
and it has been removed as of this release. See "Removed APIs" for
additional information.


Slice-to-Visual Basic compiler
------------------------------

Ice no longer includes the Slice-to-Visual Basic compiler. Given the
language-neutral nature of .NET's Common Language Runtime (CLR),
maintaining Slice compilers for both Visual Basic and C# is
unnecessary.

Users can write an Ice application in any language that is supported
by the CLR, but Slice definitions must now be generated in C#. For
this reason, we have renamed Ice for C# to Ice for .NET.


Upgrading your application
==========================

Ice 3.3.0 does not maintain backward binary compatibility with
applications built using Ice 3.2.x, but every effort was made to
preserve source compatibility. Note however that Ice always maintains
protocol ("on the wire") compatibility with prior releases.

The requirements for upgrading depend on the language mapping used by
your application:

- For statically-typed languages (C++, Java, .NET), the application
  must be recompiled. 

- For scripting languages that use static translation, your Slice
  files must be recompiled.

If your application uses IceStorm or IceGrid, please refer to the
relevant sections below for migration instructions.

Finally, certain APIs that were deprecated in previous Ice releases
have been removed in this release. If your application relied on one
of these APIs, it may no longer compile or execute correctly. A list
of the removed APIs is provided in the section titled "Removed APIs"
along with a description of their replacements. Furthermore, the
section "Deprecated APIs" discusses APIs that are deprecated as of
this release; we encourage you to update your applications and
eliminate the use of these APIs as soon as possible.


Migrating IceStorm databases
----------------------------

Ice 3.3 supports migrating IceStorm databases from Ice 3.1.1 and from
Ice 3.2.1. Migration from other Ice versions may work, but is not
officially supported. If you require assistance with this please
contact sales@zeroc.com.

To migrate, first stop your IceStorm servers.

Next, copy the IceStorm database environment to a second location:

$ cp -r db recovered.db

Run the Berkeley DB utility db_recover on the copied database
environment:

$ db_recover -h recovered.db

Note that it is essential that the correct version of db_recover is
used. For Ice 3.1.1, Berkeley DB 4.3.29 must be used. For Ice 3.2.1,
Berkeley DB 4.5 must be used.

Now change to the location where the Ice 3.3 IceStorm database
environments are stored:

$ cd <new-location>

Next, run the icestormmigrate utility. The first argument is the path
to the old database environment. The second argument is the path to
the new database environment.

In this example we'll create a new directory "db" in which to store
the migrated database environment:

$ mkdir db
$ icestormmigrate <path-to-recovered.db> db

The migration is now complete, and the contents of the old database
environment are now in the db directory.


Migrating IceGrid databases
---------------------------

Ice 3.3 supports migrating IceGrid databases from Ice 3.1.1 and from
Ice 3.2.1. Migration from other Ice versions may work, but is not
officially supported. If you require assistance with this please
contact sales@zeroc.com.

To migrate, first stop the IceGrid registry you wish to upgrade.

Next, copy the IceGrid database environment to a second location:

$ cp -r db recovered.db

Run the Berkeley DB utility db_recover on the copied database
environment:

$ db_recover -h recovered.db

Note that it is essential that the correct version of db_recover is
used. For Ice 3.1.1, Berkeley DB 4.3.29 must be used. For Ice 3.2.1,
Berkeley DB 4.5 must be used.

Now change to the location where the Ice 3.3 IceGrid database
environments are stored:

$ cd <new-location>

Next, run the upgradeicegrid.py utility located in the `config'
directory of your Ice distribution (or in /usr/share/Ice-3.3.0 if
using an RPM installation). The first argument is the path to the old
database environment. The second argument is the path to the new
database environment.

In this example we'll create a new directory "db" in which to store
the migrated database environment:

$ mkdir db
$ upgradeicegrid.py <path-to-recovered.db> db

The migration is now complete, and the contents of the old database
environment are now in the db directory. 

By default, the migration utility assumes that the servers deployed
with IceGrid also use Ice 3.3.0. If your servers still use an older
Ice version, you need to specify the --server-version command-line
option when running upgradeicegrid.py:

$ upgradeicegrid.py --server-version 3.2.1 <path-to-recovered.db> db

The migration utility will set the server descriptor `ice-version'
attribute to the specified version and the IceGrid registry will
generate configuration files compatible with the given version.

If upgrading the master IceGrid registry in a replicated environment
and the slaves are still running, you should first restart the master
registry in read-only mode using the --readonly option, for example:

$ icegridregistry --Ice.Config=config.master --readonly

Next, you can connect to the master registry with icegridadmin or the
IceGrid administrative GUI to ensure that the database is correct. If
everything looks fine, you can shutdown and restart the master
registry without the --readonly option.


Removed APIs
------------

TBD

* Thread per connection

  The primary purpose of this concurrency model was to serialize the
  requests received over a connection, either because the application
  needed to ensure that requests are dispatched in the order they are
  received, or because the application did not want to implement the
  synchronization that might be required when using the thread pool
  concurrency model.

  Another reason for using the thread-per-connection concurrency model
  is that it was required by the IceSSL plug-ins for Java and C#. This
  requirement has been eliminated.

  The ability to serialize requests is now provided by the thread pool
  and enabled via a new configuration property:

  <threadpool>.Serialize=1

  Please refer to the "Ice Run Time" chapter of the Ice manual for
  more details on this feature.

  Aside from the potential semantic changes involved in migrating your
  application to the thread pool concurrency model, other artifacts of
  thread-per-connection may be present in your application and must be
  removed:

  - The configuration properties Ice.ThreadPerConnection and
    <proxy>.ThreadPerConnection

  - The proxy methods ice_threadPerConnection and
    ice_isThreadPerConnection


Deprecated APIs
---------------

The Ice APIs and components listed below are deprecated in this
release. They will be supported for at least one more major (TBD)
release; for example, these items will be supported in Ice 3.4 and
removed in Ice 3.5. We encourage you to update your applications
and eliminate the use of these APIs as soon as possible.

TBD

* Java2 language mapping

  Java5 is now the default language mapping. Applications that use the
  Java2 mapping can continue to use it by adding the appropriate
  metadata tag to your Slice files or by using the "--meta java:java2"
  option when running the Slice-to-Java compiler. Note that the
  compiler now emits a deprecation warning when it encounters the
  Java2 metadata tag.

  If you used the "java:java5" metadata tag when compiling your Slice
  definitions, you can now remove those tags. Any uses of custom type
  metadata ("java:type:...") should also be reviewed.

* Ice.MonitorConnections

* LocalObject (Java/C#/Python)
